{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf7bbf2",
   "metadata": {},
   "source": [
    "# Feb. 2nd- Text Classification from Scratch\n",
    "\n",
    "Learned basics of TextVectorization, Embedding, more on preprocessing (tf.data.Dataset), and practiced more with keras.Model functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e484f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 17:49:25.905545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcfa6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  1457k      0  0:00:56  0:00:56 --:--:-- 1756k 1066k      0  0:01:16  0:00:17  0:00:59 1998k0:00:44  0:00:36  0:00:08 2351k   0  0:00:51  0:00:43  0:00:08  131k0:00:51  0:00:06  745k434k      0  0:00:57  0:00:52  0:00:05  934k\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "\n",
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61ea399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove subfolders we don't need \n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10eb68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 17:57:33.346658: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "# use tf.data.Dataset to split into train, test, validation set\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\",\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db435eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'I am very disappointed with \"K-911.\" The original \"good\" quality of \"K-9\" doesn\\'t exist any more. This is more like a sitcom! Some of casts from original movie returned and got some of my memory back. The captain of Dooley now loves to hit him like a scene from old comedy show. That was crazy. What\\'s the deal with the change of Police? It seems like they are now LAPD! Not San Diego PD. It is a completely different movie from \"'\n",
      "0\n",
      "b\"Giallo fans, seek out this rare film. It is well written, and full of all sorts of the usual low lifes that populate these films. I don't want to give anything away, so I wont even say anything about the plot. The whole movie creates a very bizarre atmosphere, and you don't know what to expect or who to suspect. Recommended! The only place I've seen to get this film in english is from European Trash Cinema, for $15.\"\n",
      "1\n",
      "b\"Terry Gilliam's and David Peoples' teamed up to create one of the most intelligent and creative science fiction movies of the '90's. People's proved a screenplay with bizarre twists and fantastic ideas about the nature of time \\xc2\\x97 I especially love the idea one can't change the past; it's a nice counterpoint to so many time-travelling movies which say otherwise \\xc2\\x97 biological holocausts and the thin line between sanity and madness. Gilliam visualized his ideas with unique quirkiness, perfection and originality.<br /><br />The story itself is engaging: one man, James Cole (played by Bruce Willis in a heart-warming performance) travels several decades to the past to retrieve information about a virus that's wiped out mankind and left only a few survivors alive living underground: with the information he'll collect, scientists hope to find a cure so everyone in the future can return to the surface. But because their time-travelling technology isn't perfect, he ends up being sent towards different other pasts and complicating things. And from that a brilliant science fiction thriller with shades of film noir ensues as the multiple pieces of a huge jigsaw start fitting together to form a bizarre narrative involving animal right activists, end of the millennium paranoia, biological weapons, the perception of reality, and the definition of sanity. With such a complex movie, it was easy for Gilliam and Peoples to create a mess, but instead Twelve Monkeys is a thought-provoking narrative which will please those who like to be challenged and have patience to appreciate some crazy ideas.<br /><br />I watched this movie once around 10 years ago. It marked me a lot: I remember still thinking about many days after-wards; for my young mind this seemed quite mind-blowing and it was one of the first movies to make me appreciate cinema as something serious and important. I've re-watched this movie a few days ago on DVD and it's better than I remembered it. Brad Pitt still steals all the scenes he's in, playing Jeffrey Goines \\xc2\\x97 almost a prelude to his Tyler Durden character in Fight Club \\xc2\\x97 a rich kid with some anarchist/non-conformist ideas who's also crazy and, according to Cole, perhaps responsible for the virus. The scenes between Jeffrey and Cole in the madhouse are the best in the movie, Pitt's eyes, voice and quirky mannerisms convince you he's really a crazy guy locked in a warped logic only he understands. Pitt's Oscar nomination was well deserved! Surprising was also Bruce Willis' performance: his I didn't remember very well, but it's beautiful and full of sensibility; he plays a man who spent almost all his life underground, and when he comes to the past you'll share his childish fascination with something as simple as breathing the fresh air of the morning or watching the sun go up. Cole is a rather ambiguous character, Peoples' tried to imbue some darkness in him, and he does other disturbing things to other people and to himself: the scene where he removes his own teeth reveals how far his dementia has gone unchecked. Ironically Cole didn't start as a crazy character, but when he starts warning everyone about the end of the world, he's considered mad and convinced it's all in his mind, until he arrives at a point when he can't distinguish past from future, reality from fiction. Willis spends a lot of time looking confused and insecure, and it works perfectly. One of the fun twists in the narrative is when Cole's shrink, Dr. Kathryn Railly, finds undeniable proof he's really from the future and now has to convince him again of his mission to save the world. The screenplay is full with weird twists like this and it keeps the movie in a fast pace. Their relationship is also well-handed, although perhaps a bit compressed for time's sake. But I enjoyed watching Cole and Railly falling in love and trying to escape the authority of the future to live a peaceful life in the past. But then things end in a tragic/bittersweet climax at an airport, wrapping all the pieces together, which will blow many minds away.<br /><br />There are two great endings in this movie, a twist in the sense of Se7en or Fight Club, and a more intimate ending where Railly is crouching next to Cole who's just been shot and looking around for a younger James Cole who's witnessing his future self die; the two share a brief look, and she smiles at him. The twist is brilliant, but I prefer this ending for emotional impact. Madeleine Stowe is very good playing Dr. Railly, she drew many different emotions from me in her performance. The movie is filled with a sense of fatalism with the idea the past can't be changed: this movie shows that in a terrifying way. It reminds me of Chinatown in that sense, the way Jake Gittes messes everything up the more he tries to help. Railly's character shares that fatalism, the more she tries to help Cole \\xc2\\x97 first dealing with his 'madness' then helping him in his mission \\xc2\\x97 the more they're sucked into tragedy.<br /><br />The twist ends with a hopeful note, though, with the feeling Cole's mission hasn't been in vain. Twelve Monkeys is a great movie to watch if one wants to be entertained; it's not supposed to be art, although it's more artists than many artistic movies. It's an unpretentious movie where all elements, from music to editing to costume design, etc., came together beautifully to produce a modern cinema masterpiece.\"\n",
      "1\n",
      "b\"We expected something great when we went to see this bomb. It is basically a Broadway play put on film. The music is plain terrible. There isn't one memorable song in the movie -- heard any hits from this movie? You won't because there aren't any. Some of the musical numbers go on so long that I got up to go to the restroom and get some pop corn and it was still going when I got back! If they were good songs well -- but they suck. The pace is slow, terrible character development. The lead was praised for her singing but sounded like she screamed every song -- it was almost impossible to stand. This movie has NOTHING to offer anyone but die-hard Broadway enthusiasts. This is without a doubt the most over rated movie I've seen in my entire life. A complete waist of time and money. There is nothing memorable about this movie except Danny Glover -- who wasn't on screen enough and whose character wasn't developed enough. Rent the video and you'll agree -- this movie was an expensive, over produced, polished dog do.\"\n",
      "0\n",
      "b'I understand this movie was made on a very low budget but that is no excuse for the monstrosity that is Grendel. Deathstalker, The Throne of Fire, Barbarian Queen, Conquest, the Invincible Barbarian were all done on shoestring budgets and poor special effects yet they still managed to create cult classics by adding some scantily clad women warriors and a good sense of humor. The primitive costumes, dark castles and beautiful Bulgarian landscape gave Grendel the potential to be a very good low budget sword and sorcery film, but the makers completely ruined this opportunity by using extremely poor CGI effects and colorless characters. Compare this film to Beowulf (1999). It may not be Citizen Kane but it is a good example of how an entertaining low budget sci-fi/ adventure movie can be made by using credible special effects and appealing characters.'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#look at a few examples\n",
    "#take(1) just return tf.data.Dataset with size 1\n",
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])\n",
    "#we notice there are HTML <br> tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d4c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    #replace <br /> with space\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "# TextVectorization layer to map to int; we also use our function above\n",
    "# to apply to texst as well\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    #max size of vocabulary\n",
    "    max_tokens=20000,\n",
    "    #output in int\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# only text, no labels\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "\n",
    "# create vocabulary\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51719f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "\n",
    "# Vectorize the data.\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d61e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_features = 20000\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# map vocabulary indices into embedding space\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "#  vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# prediction\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "# uses keras.Model\n",
    "model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb62970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.5067 - accuracy: 0.7109 - val_loss: 0.3084 - val_accuracy: 0.8706\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.2264 - accuracy: 0.9104 - val_loss: 0.3401 - val_accuracy: 0.8670\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.1096 - accuracy: 0.9600 - val_loss: 0.4320 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ebf0820>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2de501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 12ms/step - loss: 0.4494 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44944557547569275, 0.8636400103569031]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b47266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
